# Backbone CNN settings
[BACKBONE]
    # Backbone network architecture name
    str-BACKBONE = resnet18

    # Provide a path to backbone weights (with no top) file or ``imagenet``
    # If you want to initialize the backbone with random weights, then use ``None``
    str-BACKBONE_WEIGHTS = imagenet

    # Either 'default' or tuple of layer names
    # For example, if your backbone model is ``vgg16``,
    # tuple-FEATURE_LAYERS = ("block5_conv3", "block4_conv3", "block3_conv3", "block2_conv2", "block1_conv2")
    # which will give the same result as str-FEATURE_LAYERS = default
    str-FEATURE_LAYERS = default

# Input settings
[INPUT]
    # Number of classification classes (including background)
    int-NUM_CLASSES = 2

    # The width and height of the input tensor
    # Note that input tensor must be square shaped
    int-IMAGE_SIZE = 512

    # Number of images to train with on each GPU. A 12GB GPU can typically
    # handle 2 images of 1024x1024px.
    # Adjust based on your GPU memory and image sizes. Use the highest
    # number that your GPU can handle for best performance.
    int-IMAGES_PER_GPU = 2
    list-GPU_IDS = [0]

# The segmentation model to use
[MODEL]
    str-MODEL = maskrcnn
    str-MODE = training

# MaskRCNN: Input preprocessing
[PREPROCESSING]

    # If enabled, resizes instance masks to a smaller size to reduce
    # memory load. Recommended when using high-resolution images.
    bool-USE_MINI_MASK = True

    # (height, width) of the mini-mask
    tuple-MINI_MASK_SHAPE = (64, 64)

# MaskRCNN: Detection settings
[DETECTION]
    # Max number of final detections
    int-DETECTION_MAX_INSTANCES = 100

    # Minimum probability value to accept a detected instance
    # ROIs below this threshold are skipped
    float-DETECTION_MIN_CONFIDENCE = 0.7

    # Non-maximum suppression threshold for detection
    float-DETECTION_NMS_THRESHOLD = 0.3

    # Bounding box refinement standard deviation for Detection (Target) Layer
    list-BBOX_STD_DEV = [0.1, 0.1, 0.3, 0.3]

# MaskRCNN: Feature Pyramid Network settings
[FPN]
    # Size of the fully-connected layers in the classification graph
    int-FPN_CLASSIF_FC_LAYERS_SIZE = 512

    # Size of the top-down layers used to build the feature pyramid
    int-TOP_DOWN_PYRAMID_SIZE = 256

# MaskRCNN: Head settings
[HEAD]
    # Number of ROIs per image to feed to classifier/mask heads
    # The Mask RCNN paper uses 512 but often the RPN doesn't generate
    # enough positive proposals to fill this and keep a positive:negative
    # ratio of 1:3. You can increase the number of proposals by adjusting
    # the RPN NMS threshold.
    int-TRAIN_ROIS_PER_IMAGE = 200

    # Percent of positive ROIs used to train classifier/mask heads
    float-ROI_POSITIVE_RATIO = 0.33

    # Pooled ROIs
    int-POOL_SIZE = 7
    int-MASK_POOL_SIZE = 14

    # Shape of output mask
    # To change this you also need to change the neural network mask branch
    list-MASK_SHAPE = [28, 28]

    # Maximum number of ground truth instances to use in one image
    int-MAX_GT_INSTANCES = 100

# MaskRCNN: Non-Maximum Suppression settings
[NMS]
    # ROIs kept after tf.nn.top_k and before non-maximum suppression
    int-PRE_NMS_LIMIT = 6000

    # ROIs kept after non-maximum suppression (training and inference)
    int-POST_NMS_ROIS_TRAINING = 2000
    int-POST_NMS_ROIS_INFERENCE = 1000

# MaskRCNN: Region Proposal Network settings
[RPN]
    # Required for anchor generation
    list-BACKBONE_STRIDES = [4, 8, 16, 32, 64]

    # Length of square anchor side in pixels
    tuple-RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)

    # Ratios of anchors at each cell (width/height)
    # A value of 1 represents a square anchor, and 0.5 is a wide anchor
    list-RPN_ANCHOR_RATIOS = [0.25, 0.5, 1, 2, 4]

    # Anchor stride
    # If 1 then anchors are created for each cell in the backbone feature map.
    # If 2, then anchors are created for every other cell, and so on.
    int-RPN_ANCHOR_STRIDE = 1

    # Non-max suppression threshold to filter RPN proposals.
    # You can increase this during training to generate more propsals.
    float-RPN_NMS_THRESHOLD = 0.7

    # How many anchors per image to use for RPN training
    int-RPN_TRAIN_ANCHORS_PER_IMAGE = 256

    # Bounding box refinement standard deviation for RPN and final detections.
    list-RPN_BBOX_STD_DEV = [0.1, 0.1, 0.3, 0.3]
 
