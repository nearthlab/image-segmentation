# Backbone CNN settings
[BACKBONE]
    # Backbone network architecture name
    str-BACKBONE = resnet18

    # Provide a path to backbone weights (with no top) file or ``imagenet``
    # If you want to initialize the backbone with random weights, then use ``None``
    str-BACKBONE_WEIGHTS = imagenet

    # Either 'default' or tuple of layer names
    # For example, if your backbone model is ``vgg16``,
    # tuple-FEATURE_LAYERS = ("block5_conv3", "block4_conv3", "block3_conv3", "block2_conv2", "block1_conv2")
    # which will give the same result as str-FEATURE_LAYERS = default
    str-FEATURE_LAYERS = default

# Input settings
[INPUT]
    # Number of classification classes (including background)
    int-NUM_CLASSES = 31

    # The width and height of the input tensor
    # Note that input tensor must be square shaped
    int-IMAGE_SIZE = 512

    # Number of images to train with on each GPU. A 12GB GPU can typically
    # handle 2 images of 1024x1024px.
    # Adjust based on your GPU memory and image sizes. Use the highest
    # number that your GPU can handle for best performance.
    int-IMAGES_PER_GPU = 2
    # List of integer valued IDs of GPUs you want to use.
    list-GPU_IDS = [0]

# The segmentation model to use
[MODEL]
    str-MODEL = unet
    str-MODE = training

# Unet parameters
[UNET]
    # tuple of numbers of ``Conv2D`` layer filters in decoder blocks
    tuple-DECODER_FILTERS = (256, 128, 64, 32, 16)

    # if ``True``, ``BatchNormalization`` layer between ``Conv2D`` and ``Activation`` layers is used.
    bool-DECODER_USE_BATCHNORM = True

    # one of blocks with following layers structure
    # * `upsampling`:  ``Upsampling2D`` -> ``Conv2D`` -> ``Conv2D``
    # * `transpose`:   ``Transpose2D`` -> ``Conv2D``
    str-DECODER_BLOCK_TYPE = 'upsampling'

    # name of one of ``keras.activations`` for last model layer
    # (e.g. ``sigmoid``, ``softmax``, ``linear``).
    str-LAST_ACTIVATION = sigmoid

